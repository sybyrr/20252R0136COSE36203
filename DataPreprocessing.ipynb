{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEoFNKgta22c",
        "outputId": "7afa0ecd-296e-450a-c363-65de2167de6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "catboost_info\t\t MLProject_Progress.ipynb     ModelTraining.ipynb\n",
            "DataPreprocessing.ipynb  MLTeamPredictionBasic.ipynb  Untitled0.ipynb\n",
            "dataset\t\t\t ModelTraining_0941.ipynb     zips\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# # for colab environment\n",
        "# from google.colab import drive\n",
        "# !ls /content/drive/MyDrive/projects/ML_FinalProj\n",
        "# import sys\n",
        "# import os\n",
        "\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# sys.path.append('/content/drive/MyDrive/projects/ML_FinalProj')\n",
        "\n",
        "# os.chdir(\"/content/drive/MyDrive/projects/ML_FinalProj\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7dCYAydbOjl"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "ROOT = Path(\"dataset\")\n",
        "# import\n",
        "TEAM_STAT_PATH = ROOT / \"team-stat\"\n",
        "GAME_LOG_PATH = ROOT / \"game-log\"\n",
        "PITCHER_PATH = ROOT / \"pitcher\" / \"sp_yearly_game\"\n",
        "BATTER_PATH = ROOT / \"batting_average\"\n",
        "TOTAL_TEAM_STAT_PATH = TEAM_STAT_PATH / \"01-25_팀기록.csv\"\n",
        "\n",
        "# export\n",
        "PROCESSED_PATH = ROOT / \"processed\"\n",
        "final_dataset_path = PROCESSED_PATH / \"final_dataset_v1.csv\"\n",
        "team_features_path = PROCESSED_PATH / \"team_features_v1.csv\"\n",
        "final_base_path = PROCESSED_PATH / \"final_dataset_no_diff_v1.csv\"\n",
        "final_dataset_path = PROCESSED_PATH / \"final_dataset_with_diff_v1.csv\"\n",
        "\n",
        "PROCESSED_PATH.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_qQeSfmfG7w"
      },
      "outputs": [],
      "source": [
        "# 팀명->id 전처리용\n",
        "# 코드 전체에서 동일한 mapping 적용\n",
        "team_groups = {\n",
        "    0: ['KIA', '해태', '해태타이거즈', '해태 타이거즈', '기아', '기아타이거즈', '기아 타이거즈', 'KIA 타이거즈', 'KIA타이거즈'],\n",
        "    1: ['삼성', '삼성라이온즈', '삼성 라이온즈'],\n",
        "    2: ['두산', '두산베어스', '두산 베어스'],\n",
        "    3: ['LG', 'LG 트윈스', 'LG트윈스'],\n",
        "    4: ['KT', 'KT 위즈', 'KT위즈'],\n",
        "    5: ['SSG', 'SK', 'SSG랜더스', 'SSG 랜더스', 'SK와이번스', 'SK 와이번스'],\n",
        "    6: ['롯데', '롯데자이언츠', '롯데 자이언츠'],\n",
        "    7: ['한화', '한화이글스', '한화 이글스'],\n",
        "    8: ['NC', 'NC다이노스', 'NC 다이노스'],\n",
        "    9: ['키움', '넥센', '우리', '히어로즈', '키움 히어로즈', '키움히어로즈', '우리 히어로즈', '우리히어로즈', '넥센 히어로즈', '넥센히어로즈'],\n",
        "    10: ['현대', '현대유니콘스', '현대 유니콘스']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCzo54VMbOoc"
      },
      "outputs": [],
      "source": [
        "# 팀기록 처리\n",
        "\n",
        "team_stat_df = pd.read_csv(TOTAL_TEAM_STAT_PATH)\n",
        "teams = team_stat_df[\"team\"]\n",
        "team_names = [t[2:] for t in teams]\n",
        "unique_team_names = np.unique(team_names)\n",
        "\n",
        "\n",
        "team_stat_df_edited = team_stat_df.drop(columns=[\"wRC+.y\", \"G.x\", \"G.y\", \"G.x.x\", \"G.y.y\", \"HR.y\", \"R/ePA.y\",\n",
        "                                                 \"IsoP.y\", \"ERA.y\", \"RA9.y\", \"FIP.y\", \"rRA9.y\"]) # 중복제거\n",
        "team_stat_df_edited = team_stat_df_edited.drop(columns=[\"POSAdj\", \"RAAwithPOS\", \"WAAwithPOS\", \"HR/FB\", \"WAR당 연봉.y\"]) # 결측치 존재하는 column 제거\n",
        "# 일부 column 이름 정리\n",
        "team_stat_df_edited = team_stat_df_edited.rename(columns={\"wRC+.x\": \"wRC+\"})\n",
        "team_stat_df_edited = team_stat_df_edited.rename(columns={\"R/ePA.x\": \"R/ePA\"})\n",
        "team_stat_df_edited = team_stat_df_edited.rename(columns={\"IsoP.x\": \"IsoP\"})\n",
        "team_stat_df_edited = team_stat_df_edited.rename(columns={\"ERA.x\": \"ERA\"})\n",
        "team_stat_df_edited = team_stat_df_edited.rename(columns={\"RA9.x\": \"RA9\"})\n",
        "team_stat_df_edited = team_stat_df_edited.rename(columns={\"FIP.x\": \"FIP\"})\n",
        "team_stat_df_edited = team_stat_df_edited.rename(columns={\"rRA9.x\": \"rRA9\"})\n",
        "team_stat_df_edited = team_stat_df_edited.rename(columns={\"WAR당 연봉.x\": \"WAR당 연봉\"})\n",
        "\n",
        "# 팀 이름 / 연도 분리\n",
        "team_stat_df_edited.insert(loc=1, column=\"year\", value=team_stat_df_edited[\"team\"].str[:2])\n",
        "team_stat_df_edited.insert(loc=2, column=\"name\", value=team_stat_df_edited[\"team\"].str[2:])\n",
        "\n",
        "# 팀 이름 id 할당\n",
        "name_to_id = {name: group_id for group_id, names in team_groups.items() for name in names} # 팀 이름 -> id 변환 mapping\n",
        "team_stat_df_edited.insert(loc=0, column='id', value=team_stat_df_edited['name'].map(name_to_id))\n",
        "team_stat_df_edited = team_stat_df_edited.drop(columns=[\"team\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CrA8bp0bOqR"
      },
      "outputs": [],
      "source": [
        "# id, year별로 year-1년까지의 모든 지표 가중합하여 전처리\n",
        "def build_decayed_team_features(df, decay, exclude_cols=(\"id\", \"year\", \"name\", \"G\")):\n",
        "    suffix = \"_decay\"\n",
        "\n",
        "    df_out = df.copy()\n",
        "    df_out[\"year\"] = pd.to_numeric(df_out[\"year\"], errors='raise')\n",
        "    df_out = df_out.sort_values([\"id\", \"year\"], kind=\"mergesort\")\n",
        "    cand_cols = [c for c in df_out.columns if c not in exclude_cols]\n",
        "\n",
        "    # 연도 고려하여 각 지표의 decay 누적 계산 (가중 평균 적용)\n",
        "    # input: pd.DataFrame     output: pd.Series\n",
        "    def _decayed_cumsum_with_gaps(sub, col):\n",
        "        years = sub[\"year\"].to_numpy()\n",
        "        vals = pd.to_numeric(sub[col], errors=\"coerce\").fillna(0).to_numpy(dtype=float)\n",
        "        out = np.zeros_like(vals)\n",
        "\n",
        "        s = 0.0\n",
        "        w = 0.0\n",
        "        prev_year = None\n",
        "\n",
        "        for i in range(len(vals)):\n",
        "            if prev_year is None:\n",
        "                gap_decay = 1.0\n",
        "            else:\n",
        "                gap = int(years[i] - prev_year)\n",
        "                gap_decay = decay ** max(1, gap)\n",
        "\n",
        "            prev_val = vals[i-1] if i > 0 else 0.0\n",
        "            current_weight = 1.0 if i > 0 else 0.0\n",
        "\n",
        "            s = s * gap_decay + prev_val\n",
        "            w = w * gap_decay + current_weight\n",
        "            if w > 0:\n",
        "                out[i] = s / w\n",
        "            else:\n",
        "                out[i] = 0.0\n",
        "\n",
        "            prev_year = years[i]\n",
        "\n",
        "        return pd.Series(out, index=sub.index)\n",
        "\n",
        "    new_cols_list = []\n",
        "\n",
        "    for col in cand_cols:\n",
        "        new_col = f\"{col}{suffix}\"\n",
        "\n",
        "        new_series = (\n",
        "            df_out.groupby(\"id\", group_keys=False).apply(\n",
        "                lambda x: _decayed_cumsum_with_gaps(x, col),\n",
        "                include_groups=False\n",
        "            )\n",
        "        )\n",
        "        new_series.name = new_col\n",
        "        new_cols_list.append(new_series)\n",
        "\n",
        "    df_out = pd.concat([df_out] + new_cols_list, axis=1)\n",
        "    return df_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NP8eqNQ0D6mj"
      },
      "outputs": [],
      "source": [
        "# game-log csv 불러오기 및 정렬\n",
        "game_log_csv_names = [\"games_20\" + str(i).zfill(2) + \".csv\" for i in range(2, 26)]\n",
        "game_log_df = pd.DataFrame()\n",
        "\n",
        "for i in range(2, 26):\n",
        "  GAME_LOG_PATH_PER_YEAR = GAME_LOG_PATH / game_log_csv_names[i-2]\n",
        "  game_log_per_year_df = pd.read_csv(GAME_LOG_PATH_PER_YEAR)\n",
        "  game_log_df = pd.concat([game_log_df, game_log_per_year_df])\n",
        "\n",
        "# game-log에서 팀 이름을 id로 변환\n",
        "game_log_df = game_log_df.assign(\n",
        "    home_id = game_log_df[\"home_team\"].map(name_to_id),\n",
        "    away_id = game_log_df[\"away_team\"].map(name_to_id),\n",
        ")\n",
        "\n",
        "### 해당 시즌 내 지표(~승률, 최근10경기) 계산\n",
        "game_log_base = game_log_df[['date', 'season', 'home_id', 'away_id', 'home_runs', 'away_runs']].dropna(subset=['home_id', 'away_id'])\n",
        "game_log_base['home_id'] = game_log_base['home_id'].astype(int)\n",
        "game_log_base['away_id'] = game_log_base['away_id'].astype(int)\n",
        "\n",
        "home_games = game_log_base.rename(columns={'home_id': 'team_id', 'away_id': 'opp_id'})\n",
        "home_games['win'] = (home_games['home_runs'] > home_games['away_runs']).astype(int)\n",
        "away_games = game_log_base.rename(columns={'away_id': 'team_id', 'home_id': 'opp_id'})\n",
        "away_games['win'] = (away_games['away_runs'] > away_games['home_runs']).astype(int)\n",
        "\n",
        "all_games_df = pd.concat([\n",
        "    home_games[['date', 'season', 'team_id', 'win']],\n",
        "    away_games[['date', 'season', 'team_id', 'win']]\n",
        "])\n",
        "all_games_df = all_games_df.sort_values(by=['team_id', 'date'])\n",
        "\n",
        "# 해당 시즌 누적 승률(직전 경기까지 반영)\n",
        "gb_season = all_games_df.groupby(['team_id', 'season'])\n",
        "wins_season_total = gb_season['win'].cumsum()\n",
        "games_season_total = gb_season.cumcount() + 1\n",
        "prev_wins = wins_season_total.shift(1).fillna(0)\n",
        "prev_games = games_season_total.shift(1).fillna(0)\n",
        "all_games_df['in_season_win_rate'] = (prev_wins / prev_games).fillna(0)\n",
        "\n",
        "# 최근 10경기 승률\n",
        "gb_team = all_games_df.groupby('team_id')\n",
        "all_games_df['L10_win_rate'] = gb_team['win'].shift(1).rolling(\n",
        "    window=10, min_periods=1\n",
        ").mean().reset_index(level=0, drop=True).fillna(0)\n",
        "\n",
        "# 병합\n",
        "stats_to_merge = all_games_df.drop_duplicates(\n",
        "    subset=['date', 'season', 'team_id'], keep='last'\n",
        ")\n",
        "stats_to_merge = stats_to_merge[['date', 'season', 'team_id', 'in_season_win_rate', 'L10_win_rate']]\n",
        "\n",
        "# 지표별 decay 적용\n",
        "team_stat_df_edited = build_decayed_team_features(\n",
        "    team_stat_df_edited,\n",
        "    decay=0.9\n",
        ")\n",
        "feature_cols = ['id', 'year'] + [col for col in team_stat_df_edited.columns if col.endswith(\"_decay\")]\n",
        "team_features_df = team_stat_df_edited[feature_cols].copy()\n",
        "\n",
        "home_features = team_features_df.rename(columns={\n",
        "    col: f\"home_{col}\" for col in team_features_df.columns if col not in ['id', 'year']\n",
        "})\n",
        "away_features = team_features_df.rename(columns={\n",
        "    col: f\"away_{col}\" for col in team_features_df.columns if col not in ['id', 'year']\n",
        "})\n",
        "\n",
        "# game-log 전처리\n",
        "game_log_df_cleaned = game_log_df.dropna(subset=[\"home_id\", \"away_id\"]).copy()\n",
        "game_log_df_cleaned['year'] = (game_log_df_cleaned['season'] % 100).astype(int)\n",
        "game_log_df_cleaned['home_id'] = game_log_df_cleaned['home_id'].astype(int)\n",
        "game_log_df_cleaned['away_id'] = game_log_df_cleaned['away_id'].astype(int)\n",
        "game_log_df_cleaned['home_win'] = (game_log_df_cleaned['home_runs'] > game_log_df_cleaned['away_runs']).astype(int)\n",
        "game_data_df = game_log_df_cleaned[['date', 'season', 'year', 'home_id', 'away_id', 'home_runs', 'away_runs', 'home_win']]\n",
        "\n",
        "# game-log와 연도별 지표 결합\n",
        "merged_df = pd.merge(\n",
        "    game_data_df, home_features,\n",
        "    left_on=['home_id', 'year'], right_on=['id', 'year'], how='left'\n",
        ")\n",
        "final_df = pd.merge(\n",
        "    merged_df, away_features,\n",
        "    left_on=['away_id', 'year'], right_on=['id', 'year'], how='left'\n",
        ")\n",
        "final_df = final_df.drop(columns=['id_x', 'id_y'])\n",
        "\n",
        "# 해당 연도 승률 지표 추가\n",
        "final_df_with_momentum = pd.merge(\n",
        "    final_df,\n",
        "    stats_to_merge.rename(columns={\n",
        "        'team_id': 'home_id',\n",
        "        'in_season_win_rate': 'home_in_season_win_rate',\n",
        "        'L10_win_rate': 'home_L10_win_rate'\n",
        "    }),\n",
        "    on=['date', 'season', 'home_id'], how='left'\n",
        ")\n",
        "final_df_with_momentum = pd.merge(\n",
        "    final_df_with_momentum,\n",
        "    stats_to_merge.rename(columns={\n",
        "        'team_id': 'away_id',\n",
        "        'in_season_win_rate': 'away_in_season_win_rate',\n",
        "        'L10_win_rate': 'away_L10_win_rate'\n",
        "    }),\n",
        "    on=['date', 'season', 'away_id'], how='left'\n",
        ")\n",
        "\n",
        "# 결측치 처리\n",
        "new_momentum_cols = ['home_in_season_win_rate', 'home_L10_win_rate', 'away_in_season_win_rate', 'away_L10_win_rate']\n",
        "final_df_with_momentum[new_momentum_cols] = final_df_with_momentum[new_momentum_cols].fillna(0)\n",
        "\n",
        "# 두 팀의 차이 지표\n",
        "final_df_with_diff = final_df_with_momentum.copy()\n",
        "\n",
        "# diff에 decay 적용\n",
        "decay_cols = [col for col in team_features_df.columns if col.endswith('_decay')]\n",
        "base_cols = [c for c in decay_cols if c not in ['id', 'year']]\n",
        "home_mat = final_df_with_diff[[f'home_{c}' for c in base_cols]].copy()\n",
        "home_mat.columns = base_cols\n",
        "away_mat = final_df_with_diff[[f'away_{c}' for c in base_cols]].copy()\n",
        "away_mat.columns = base_cols\n",
        "diff_arr = home_mat.values - away_mat.values\n",
        "diff_cols = [f'diff_{c}' for c in base_cols]\n",
        "diff_df = pd.DataFrame(diff_arr, columns=diff_cols, index=final_df_with_diff.index)\n",
        "final_df_with_diff = pd.concat([final_df_with_diff, diff_df], axis=1, copy=False)\n",
        "\n",
        "final_df_with_diff['diff_in_season_win_rate'] = final_df_with_diff['home_in_season_win_rate'] - final_df_with_diff['away_in_season_win_rate']\n",
        "final_df_with_diff['diff_L10_win_rate'] = final_df_with_diff['home_L10_win_rate'] - final_df_with_diff['away_L10_win_rate']\n",
        "\n",
        "final_df_with_diff = final_df_with_diff.copy()\n",
        "final_df_filtered = final_df_with_diff[final_df_with_diff['season'] > 2002].copy()\n",
        "final_df_complete = final_df_filtered.dropna() # 최종 df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edsXG4q5TAmG"
      },
      "outputs": [],
      "source": [
        "# starter csv 불러오기 및 병합\n",
        "starters_csv_names = [f\"kbo_starters_regular_season_{year}.csv\" for year in range(2002, 2026)]\n",
        "starters_df = pd.DataFrame()\n",
        "\n",
        "for year in range(2002, 2026):\n",
        "    CURRENT_PITCHER_PATH = PITCHER_PATH / f\"kbo_starters_regular_season_{year}.csv\"\n",
        "\n",
        "    if CURRENT_PITCHER_PATH.exists():\n",
        "        temp_df = pd.read_csv(CURRENT_PITCHER_PATH)\n",
        "        temp_df['year'] = year\n",
        "        starters_df = pd.concat([starters_df, temp_df], ignore_index=True)\n",
        "    else:\n",
        "        print(f\"File not found: {CURRENT_PITCHER_PATH}\")\n",
        "\n",
        "# 팀 이름 전처리 적용\n",
        "starters_df['team_id'] = starters_df['team'].map(name_to_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9XUCJHvXld_",
        "outputId": "5ba64c34-d81e-4e02-dddd-e6ccd8c8fd24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           date name   era  pre_game_era\n",
            "326  2002-05-25  가내영  1.50           NaN\n",
            "408  2002-06-08  가내영  2.89          1.50\n",
            "650  2002-07-28  가내영  3.31          2.89\n",
            "207  2002-05-04  강철민  6.10           NaN\n",
            "260  2002-05-12  강철민  7.04          6.10\n",
            "Before dropping missing pitcher data: (14279, 392)\n",
            "After dropping missing pitcher data: (12398, 392)\n"
          ]
        }
      ],
      "source": [
        "# 이전 경기까지의 ERA 병합\n",
        "starters_df['date'] = starters_df['date'].astype(str)\n",
        "starters_df['era'] = pd.to_numeric(starters_df['era'], errors='coerce')\n",
        "starters_df = starters_df.sort_values(by=['year', 'team_id', 'name', 'date'])\n",
        "starters_df['pre_game_era'] = starters_df.groupby(['year', 'team_id', 'name'])['era'].shift(1)\n",
        "print(starters_df[['date', 'name', 'era', 'pre_game_era']].head())\n",
        "\n",
        "# column 추출 및 처리\n",
        "starters_subset = starters_df[['date', 'team_id', 'pre_game_era']].copy()\n",
        "final_df_complete['date'] = final_df_complete['date'].astype(str)\n",
        "starters_subset['date'] = starters_subset['date'].astype(str)\n",
        "starters_subset = starters_subset.drop_duplicates(subset=['date', 'team_id'], keep='first')\n",
        "\n",
        "# home era 병합\n",
        "final_df_complete = pd.merge(\n",
        "    final_df_complete,\n",
        "    starters_subset.rename(columns={'team_id': 'home_id', 'pre_game_era': 'home_era'}),\n",
        "    on=['date', 'home_id'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# away era 병합\n",
        "final_df_complete = pd.merge(\n",
        "    final_df_complete,\n",
        "    starters_subset.rename(columns={'team_id': 'away_id', 'pre_game_era': 'away_era'}),\n",
        "    on=['date', 'away_id'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# diff 계산\n",
        "final_df_complete['diff_era'] = final_df_complete['home_era'] - final_df_complete['away_era']\n",
        "\n",
        "# 결측치 처리\n",
        "print(f\"Before dropping missing pitcher data: {final_df_complete.shape}\")\n",
        "final_df_complete = final_df_complete.dropna(subset=['home_era', 'away_era'])\n",
        "print(f\"After dropping missing pitcher data: {final_df_complete.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "final_df_complete['temp_date'] = pd.to_datetime(final_df_complete['date'])\n",
        "\n",
        "final_df_stable = final_df_complete[final_df_complete['temp_date'].dt.month >= 5].copy()\n",
        "final_df_complete = final_df_complete.drop(columns=['temp_date'])\n",
        "final_df_stable = final_df_stable.drop(columns=['temp_date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQYb2fRkZFlw",
        "outputId": "a3d962c8-7c46-4a0d-9ca1-b596ab8d75d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pivot completed. Shape: (28376, 11)\n",
            "         date  team_id  avg_1  avg_2  avg_3  avg_4  avg_5  avg_6  avg_7  \\\n",
            "0  2002-04-05        0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
            "1  2002-04-05        1    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
            "2  2002-04-05        2    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
            "3  2002-04-05        3    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
            "4  2002-04-05        5    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
            "\n",
            "   avg_8  avg_9  \n",
            "0    0.0    0.0  \n",
            "1    0.0    0.0  \n",
            "2    0.0    0.0  \n",
            "3    0.0    0.0  \n",
            "4    0.0    0.0  \n",
            "Final Shape: (12398, 413)\n",
            "         date  home_id  home_bat_avg  away_bat_avg  diff_bat_avg\n",
            "0  2003-04-09        6      0.172556      0.362444     -0.189889\n",
            "1  2003-04-10        2      0.244222      0.329444     -0.085222\n",
            "2  2003-04-10        7      0.255444      0.134556      0.120889\n",
            "3  2003-04-10        6      0.176556      0.341778     -0.165222\n",
            "4  2003-04-10        5      0.196000      0.262111     -0.066111\n"
          ]
        }
      ],
      "source": [
        "# 타자 데이터 병합\n",
        "BATTER_AVG_PATH = ROOT / \"batting_average\"\n",
        "batters_df_list = []\n",
        "\n",
        "for year in range(2002, 2026):\n",
        "    file_name = f\"kbo_starters_batters_{year}_final.csv\"\n",
        "    current_file_path = BATTER_AVG_PATH / file_name\n",
        "\n",
        "    if current_file_path.exists():\n",
        "        temp_batter_df = pd.read_csv(current_file_path)\n",
        "        temp_batter_df['year'] = year\n",
        "        batters_df_list.append(temp_batter_df)\n",
        "\n",
        "if batters_df_list:\n",
        "    batters_df = pd.concat(batters_df_list, ignore_index=True)\n",
        "\n",
        "    # team_id 매핑\n",
        "    if 'team' in batters_df.columns:\n",
        "        batters_df['team_id'] = batters_df['team'].map(name_to_id)\n",
        "        batters_df['date'] = batters_df['date'].astype(str)\n",
        "\n",
        "        batters_df = batters_df[batters_df['order'].isin(range(1, 10))]\n",
        "\n",
        "        batters_pivot = batters_df.pivot_table(\n",
        "            index=['date', 'team_id'],\n",
        "            columns='order',\n",
        "            values='avg',\n",
        "            aggfunc='first'\n",
        "        )\n",
        "\n",
        "        batters_pivot.columns = [f'avg_{col}' for col in batters_pivot.columns]\n",
        "        batters_wide = batters_pivot.reset_index()\n",
        "\n",
        "        print(\"Pivot completed. Shape:\", batters_wide.shape)\n",
        "        print(batters_wide.head())\n",
        "\n",
        "    else:\n",
        "        print(\"Error: 'team' column not found\")\n",
        "        batters_wide = pd.DataFrame()\n",
        "else:\n",
        "    print(\"No batter data loaded.\")\n",
        "    batters_wide = pd.DataFrame()\n",
        "\n",
        "\n",
        "if not batters_wide.empty:\n",
        "\n",
        "    # 사용할 타율 컬럼 리스트 (avg_1 ~ avg_9)\n",
        "    bat_cols = [f'avg_{i}' for i in range(1, 10)]\n",
        "\n",
        "    # Home 병합\n",
        "    home_rename_map = {col: f\"home_bat_{i+1}\" for i, col in enumerate(bat_cols)}\n",
        "    home_batters = batters_wide[['date', 'team_id'] + bat_cols].rename(\n",
        "        columns={'team_id': 'home_id', **home_rename_map}\n",
        "    )\n",
        "\n",
        "    final_df_complete = pd.merge(\n",
        "        final_df_complete,\n",
        "        home_batters,\n",
        "        on=['date', 'home_id'],\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # Away 병합\n",
        "    away_rename_map = {col: f\"away_bat_{i+1}\" for i, col in enumerate(bat_cols)}\n",
        "    away_batters = batters_wide[['date', 'team_id'] + bat_cols].rename(\n",
        "        columns={'team_id': 'away_id', **away_rename_map}\n",
        "    )\n",
        "\n",
        "    final_df_complete = pd.merge(\n",
        "        final_df_complete,\n",
        "        away_batters,\n",
        "        on=['date', 'away_id'],\n",
        "        how='left'\n",
        "    )\n",
        "    # Home 평균\n",
        "    home_bat_cols = [f\"home_bat_{i}\" for i in range(1, 10)]\n",
        "    final_df_complete['home_bat_avg'] = final_df_complete[home_bat_cols].mean(axis=1)\n",
        "\n",
        "    # Away 평균\n",
        "    away_bat_cols = [f\"away_bat_{i}\" for i in range(1, 10)]\n",
        "    final_df_complete['away_bat_avg'] = final_df_complete[away_bat_cols].mean(axis=1)\n",
        "\n",
        "    # Diff 계산\n",
        "    final_df_complete['diff_bat_avg'] = final_df_complete['home_bat_avg'] - final_df_complete['away_bat_avg']\n",
        "\n",
        "    print(\"Final Shape:\", final_df_complete.shape)\n",
        "    print(final_df_complete[['date', 'home_id', 'home_bat_avg', 'away_bat_avg', 'diff_bat_avg']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUvANOCJhWjw",
        "outputId": "da287520-dce3-46d2-9919-4d0d49040e47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before dropna: (12398, 413)\n",
            "After dropna: (12002, 413)\n",
            "Stable dataset shape (Month >= 5): (10389, 413)\n"
          ]
        }
      ],
      "source": [
        "# 결측치 제거\n",
        "print(f\"Before dropna: {final_df_complete.shape}\")\n",
        "final_df_complete = final_df_complete.dropna(subset=['home_bat_avg', 'away_bat_avg'])\n",
        "print(f\"After dropna: {final_df_complete.shape}\")\n",
        "\n",
        "if 'date' in final_df_complete.columns:\n",
        "    temp_date = pd.to_datetime(final_df_complete['date'])\n",
        "    final_df_stable = final_df_complete[temp_date.dt.month >= 5].copy()\n",
        "    print(f\"Stable dataset shape (Month >= 5): {final_df_stable.shape}\")\n",
        "else:\n",
        "    print(\"Error: 'date' column not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlWRNU5GD6pF"
      },
      "outputs": [],
      "source": [
        "# 최종 dataset\n",
        "final_df_complete.to_csv(final_dataset_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "# diff 없는 dataset\n",
        "final_base_df = final_df_with_momentum[final_df_with_momentum['season'] > 2002].dropna()\n",
        "final_base_df.to_csv(final_base_path, index=False, encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYv7596ARETF"
      },
      "outputs": [],
      "source": [
        "final_stable_dataset_path = PROCESSED_PATH / \"final_dataset_stable_v1.csv\"\n",
        "final_df_stable.to_csv(final_stable_dataset_path, index=False, encoding='utf-8-sig')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}